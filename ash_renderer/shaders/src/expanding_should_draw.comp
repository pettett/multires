#version 460

#extension GL_ARB_separate_shader_objects : enable
#extension GL_GOOGLE_include_directive : enable
#extension GL_ARB_shader_draw_parameters : require
#extension GL_KHR_shader_subgroup_arithmetic : enable
#extension GL_KHR_shader_subgroup_vote : enable
#extension GL_EXT_control_flow_attributes : require
#extension GL_EXT_debug_printf : enable
#extension GL_EXT_shader_explicit_arithmetic_types_int16 : enable

#include "structs\camera.glsl"
#include "structs\cluster_data.glsl"
#include "structs\indirect_draw_data.glsl"
#include "structs\mesh_task_payload.glsl"
#include "structs\model.glsl"
#include "structs\range.glsl"

//@group(0) @binding(0) var<storage, write> result_indicies: array<i32>;

// layout(binding = 0) writeonly buffer ResultIndicies {
//     uint result[];
// } result_indicies;

// layout(binding = 1) writeonly buffer DrawIndirectParams {
//     DrawIndexedIndirect result[];
// } draw_indirect_params;

layout(binding = 0) readonly buffer ModelUniformBufferObject {
	Model models[];
};

layout(binding = 2) readonly buffer Clusters {
	ClusterData clusters[];
};

layout(binding = 1) writeonly buffer ShouldDraw {
	uint draw_list[];
};

layout(binding = 3) readonly uniform CameraUniformBufferObject {
	CameraUniformObject ubo;
};

layout(std430, binding = 6) buffer IndirectDrawBuffer {
	IndirectDrawData indirect_draw[];
};

layout(std430, binding = 7) buffer RangeBuffer {
	Range ranges[];
};

const float LARGE_ERROR = 100000000000000000.0;

// Use minimim of co_parent errors. Causes weirdness otherwise for some reason
#define MIN_ERROR

#include "util\cluster.glsl"

#define GROUP_SPHERE // Make culling check agaisnt the bounding sphere for the entire group. Allows early exit /
					 // instance culling

#include "util\culling.glsl"

const uint LOCAL_SIZE_X = 32;

layout(local_size_x = LOCAL_SIZE_X, local_size_y = 1, local_size_z = 1) in;

const uint QUEUE_SIZE = 5000;

const uint STARTING = 32;
// Use half sized types due to limited shared storage space
shared uint16_t[QUEUE_SIZE] queue;
shared uint16_t[QUEUE_SIZE] to_draw;

// This algorithm works by exploring the bag starting from the root vertices. If a cluster cannot be drawn,
// its children are appended to the queue and every iteration of the core loop grabs that many items out of the queue
// for analysis
void main() {
	uint idx = gl_GlobalInvocationID.x;
	uint instance = gl_WorkGroupID.y;

	[[unroll]] for (int i = 0; i < STARTING; i++) { queue[i] = uint16_t(i); }

	uint queue_tail = STARTING;
	uint queue_head = 0;

	if (clusters.length() / 2 > QUEUE_SIZE) {
		while (true) {
		}
	}

	// leave some room for the number of clusters produced by the previous to increase
	// uint start = instance == 0 ? 0 : ranges[instance - 1].end + 100;

	// offset by the maximum cluster count in a mesh
	// uint start = instance * clusters.length() / 2;

	// if (subgroupElect()) {
	// 	ranges[instance].start = start;
	// }
	uint pos = 0;

	// if (subgroupElect()) {
	// 	debugPrintfEXT("Starting %v4f \n", planes[0]);
	// }

	// only evaluate if we are within the bounds of the queue
	while (queue_tail - queue_head > 0) {
		// old_queue_size = queue_tail - queue_head;

		subgroupMemoryBarrierShared();

		if (idx < queue_tail - queue_head) {
			queue_head += idx;
			uint i = queue[queue_head % QUEUE_SIZE];
			queue_head += 1;

			// should_draw[queue_head] = queue_head + 1;

			bool high_error;
			vec3 local_cam_pos;
			bool can_draw = cluster_can_draw(i, instance, local_cam_pos, high_error);

			// bool should_draw = sphere_inside_planes(planes, vec4(clusters[i].center, clusters[i].radius));

			vec4 local_pos = vec4(clusters[i].center, 1);

			// Generate object space clipping planes
			mat4 MVP = ubo.culling_view_proj * models[instance].model;

			vec4 planes[6] = planes_from_mat(MVP);

			bool should_draw_group = sphere_inside_planes(planes, vec4(clusters[i].center, clusters[i].radius));
			bool should_draw_cluster = sphere_inside_planes(planes, clusters[i].tight_sphere);

			// bool should_draw = cluster_should_draw(i, instance, local_cam_pos);

			// if (subgroupAll(draw)){
			// 	// Can just use idx instead of exclusive add for
			// simplicity
			// 	// Its pretty likely nearby clusters are drawn together
			// 	pos += idx;
			// }
			// else if (!subgroupAny(draw)){
			// 	// nothing
			// }
			// else if (draw){
			// 	pos += subgroupExclusiveAdd(1);
			// }

			if (can_draw && should_draw_cluster) {
				pos += subgroupExclusiveAdd(1);
				to_draw[pos] = uint16_t(i);
				pos += 1;
			}

			// pos += 1;

			bool can_queue_children = clusters[i].max_child_index >= STARTING;

			// add children to queue if we dont draw this and we have a
			// too high error

			if (i < clusters[i].co_parent && can_queue_children && should_draw_group && high_error) {
				// debugPrintfEXT("Min child index %d\n",
				// clusters[i].min_child_index); if
				// (clusters[i].min_child_index < i){ 	while
				// (true){}
				// }

				// add to queue

				uint min_child_index = max(clusters[i].min_child_index, STARTING);

				// Allocate ourselves space at the end of the
				// queue. max_child_index >= STARTING from before

				// queue_tail +=
				// subgroupExclusiveAdd(clusters[i].max_child_index
				// - min_child_index);

				// queue_tail += idx;

				uint children = min(MAX_CHILDREN, clusters[i].max_child_index - min_child_index + 1);

				queue_tail += subgroupExclusiveAdd(children);

				[[unroll]] for (uint c = 0; c <= children; c++) {
					// if ((queue_tail - queue_head) < QUEUE_SIZE) {
					// 	uint off = subgroupExclusiveAdd(1);
					// 	uint block = subgroupAdd(1);

					// 	queue[(queue_tail + off) % QUEUE_SIZE] = c;
					// 	queue_tail += block;
					// }

					queue[queue_tail % QUEUE_SIZE] = uint16_t(min_child_index + c);
					queue_tail += 1;
				}

				// queue[(queue_tail) % QUEUE_SIZE] =
				// clusters[i].min_child_index;
			}
		}

		pos = subgroupMax(pos);
		queue_head = subgroupMax(queue_head);
		queue_tail = subgroupMax(queue_tail);

		// if (subgroupElect()){
		// 	debugPrintfEXT("\n");
		// }
	}

	// if (subgroupElect()){ debugPrintfEXT("Finished \n"); }
	// if (subgroupElect()){ debugPrintfEXT("\n"); }

	if (subgroupElect()) {
		// for (int i = 0; i < TASK_GROUP_SIZE; i++) {
		// 	draw_list[pos + i] = 0;
		// }

		memoryBarrierBuffer();

		uint start = atomicAdd(ranges[0].end, pos + TASK_GROUP_SIZE);

		indirect_draw[instance].group_size_x = ((pos + (TASK_GROUP_SIZE - 1)) / TASK_GROUP_SIZE);

		ranges[instance + 1].start = start;
		ranges[instance + 1].end = start + pos;
	}

	subgroupMemoryBarrierBuffer();

	uint start = ranges[instance + 1].start;

	for (uint i = idx; i < pos; i += LOCAL_SIZE_X) {
		draw_list[start + i] = to_draw[i] + 1;
	}
}